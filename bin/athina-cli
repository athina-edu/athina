#!/usr/bin/env python3

# TODO: need to set defaults for some options
# TODO: Delete old comments
# TODO: switch norepo to repo

# Required modules
import sys
import json
import configparser
import argparse
import filelock
import multiprocessing
from athina.users import *
from athina.logger import *
from athina.tester import *
from athina.configuration import *

# Variable modules (extensions, e.g., canvas or blackboard)
from athina.canvas import *
from athina.git import *


def lock_process():
    # Allow only one instance
    lock_file = filelock.FileLock("/run/lock/athina.py.lock")
    try:
        lock_file.acquire(timeout=10)
    except filelock.Timeout:
        sys.exit("Another instance of athina.py is running. If this is an error, delete athina.py.lock")
    return lock_file


def parse_command_line():
    """
    Command line arguments
    :return:
    """
    parser = argparse.ArgumentParser(
        description='ATHINA - Automated Testing Homework Interface for N Assignments')
    parser.add_argument(
        '--config', metavar='c', required=False, type=str, help='Configuration File')
    parser.add_argument(
        '--verbose', metavar='v', required=False, type=bool, help='Verbose mode, default False', default=False)
    parser.add_argument(
        '--simulate', metavar='v', required=False, type=bool, help='Simulate but never submit grade', default=False)
    parser.add_argument(
        '--forced_testing', metavar='f', required=False, help='Force (re)-grading for a student name', type=str)
    parser.add_argument(
        '--repo_url_testing', metavar='r', required=False,
        help='Test a git config on a particular repo (this exclusively for testing configuration)', type=str)
    parser.add_argument(
        '--json', metavar='j', required=False, type=str, help='JSON list of folders with Athina cfg files and tests')
    args = parser.parse_args()
    return args


def find_cfg(directory):
    if os.path.isdir(directory):
        # Find a cfg file in the directory
        try:
            cfg_file = glob.glob('%s*.cfg' % directory)[0]
        except IndexError:
            cfg_file = directory  # this will fail later on but we have done all that we can
    else:
        cfg_file = directory
    return cfg_file


def check_dependencies():
    # Verify requirements are available on OS
    # TODO: docker is optional so technically unless an assignment has the flag raised it should not be needed
    software_dependencies = ["firejail", "timeout", "git", "docker"]
    for software in software_dependencies:
        if shutil.which(software) is None:
            raise FileNotFoundError("%s is not available on the host system." % software)
    return True


if __name__ == "__main__":
    # Athina's directory
    DIR_PATH = os.path.dirname(os.path.realpath(__file__))

    # Verify software dependencies
    check_dependencies()

    # Get command line parameters
    ARGS = parse_command_line()

    # Lock process so that duplicates won't run
    lock = lock_process()

    # Setup logger
    LOGGER = Logger()

    # helper_functions also imports builtins, a way to make global variable
    LOGGER.verbose = ARGS.verbose

    # Build the list of assignments to check (Athina Web = json format, command line = 1 assignment only)
    RUN_LIST = []
    if ARGS.json is not None:
        RUN_LIST = request_url(ARGS.json, method="get", return_type="json")
    elif ARGS.config is not None:
        RUN_LIST.append({'directory': ARGS.config, 'simulate': ARGS.simulate})
    else:
        raise SyntaxError("You need to provide either --config or --json.")

    # Iterate through each assignment
    for RUN_RECORD in RUN_LIST:
        # Build configuration object
        CONFIGURATION = Configuration()

        # Load Configuration
        CONFIG = configparser.ConfigParser()
        CONFIG.read(find_cfg(RUN_RECORD['directory']))

        # Read Configuration file
        CONFIGURATION.config_dir = os.path.dirname(RUN_RECORD['directory'])
        CONFIGURATION.config_filename = os.path.split(find_cfg(RUN_RECORD['directory']))[1]  # cfg filename or dir name

        # Obtain simulation parameters and specify log file
        assert type(RUN_RECORD['simulate']) is bool, \
            "Simulate is not properly read. " \
            "Either the parameter was passed wrong or the code needs fixing."
        CONFIGURATION.simulate = RUN_RECORD['simulate']
        LOGGER.log_file = "%s/%s.log" % (CONFIGURATION.config_dir, CONFIGURATION.config_filename)

        # Load arguments from config
        try:
            LOGGER.print_debug_messages = CONFIG.getboolean('main', 'print_debug_msgs')
        except configparser.NoOptionError:
            LOGGER.print_debug_messages = False
        LOGGER.vprint("Loading configuration", debug=True)
        LOGGER.vprint("Reading %s in %s" % (CONFIGURATION.config_filename, CONFIGURATION.config_dir), debug=True)
        try:
            CONFIGURATION.auth_token = CONFIG.get('main', 'auth_token')
        except configparser.NoSectionError:
            LOGGER.vprint("Unable to read config file!")
            continue  # skip to next item in RUN_LIST
        try:
            CONFIGURATION.course_id = CONFIG.getint('main', 'course_id')
        except ValueError:
            CONFIGURATION.course_id = 0
        try:
            CONFIGURATION.assignment_id = CONFIG.getint('main', 'assignment_id')
        except ValueError:
            CONFIGURATION.assignment_id = 0

        CONFIGURATION.total_points = CONFIG.getint('main', 'total_points')
        CONFIGURATION.enforce_due_date = CONFIG.getboolean('main', 'enforce_due_date')
        CONFIGURATION.test_scripts = json.loads(CONFIG.get('main', 'test_scripts'))
        CONFIGURATION.test_weights = json.loads(CONFIG.get('main', 'test_weights'))
        try:
            CONFIGURATION.moss_id = CONFIG.getint('main', 'moss_id')
        except ValueError:
            CONFIGURATION.moss_id = 0
        CONFIGURATION.moss_lang = CONFIG.get('main', 'moss_lang')
        CONFIGURATION.moss_pattern = CONFIG.get('main', 'moss_pattern')
        CONFIGURATION.git_username = CONFIG.get('main', 'git_username')
        CONFIGURATION.git_password = CONFIG.get('main', 'git_password')
        CONFIGURATION.same_url_limit = CONFIG.getint('main', 'same_url_limit')
        CONFIGURATION.check_plagiarism_hour = CONFIG.getint('main', 'check_plagiarism_hour')
        CONFIGURATION.submit_results_as_file = CONFIG.getboolean('main', 'submit_results_as_file')
        CONFIGURATION.max_file_size = CONFIG.getint('main', 'max_file_size')
        CONFIGURATION.max_file_size = CONFIGURATION.max_file_size * 1024  # Convert KB to bytes
        try:
            CONFIGURATION.test_timeout = CONFIG.getint('main', 'test_timeout')
        except configparser.NoOptionError:
            CONFIGURATION.test_timeout = 120
        try:
            CONFIGURATION.no_repo = CONFIG.getboolean('main', 'no_repo')
        except configparser.NoOptionError:
            CONFIGURATION.no_repo = False
        try:
            CONFIGURATION.pass_extra_params = CONFIG.getboolean('main', 'pass_extra_params')
        except configparser.NoOptionError:
            CONFIGURATION.pass_extra_params = False
        try:
            CONFIGURATION.grade_update_frequency = CONFIG.getint('main', 'grade_update_frequency') - 1
        except configparser.NoOptionError:
            CONFIGURATION.grade_update_frequency = 24 - 1
        try:
            CONFIGURATION.git_url = CONFIG.get('main', 'git_url')
        except configparser.NoOptionError:
            CONFIGURATION.git_url = 'gitlab.cs.wwu.edu'
        try:
            CONFIGURATION.processes = CONFIG.getint('main', 'processes')
        except configparser.NoOptionError:
            CONFIGURATION.processes = 1
        try:
            CONFIGURATION.use_docker = CONFIG.getboolean('main', 'use_docker')
        except configparser.NoOptionError:
            CONFIGURATION.use_docker = False

        # Starting statement
        LOGGER.vprint("###\nStarting - %s\n###" % datetime.now(timezone.utc).isoformat(' '))

        # Load e-learning platform functions
        E_LEARNING = Canvas(CONFIGURATION.auth_token,
                            CONFIGURATION.course_id,
                            CONFIGURATION.assignment_id,
                            LOGGER,
                            CONFIGURATION.submit_results_as_file)

        # Begin gathering data from Canvas
        USER_DATA = Users(logger=LOGGER)
        USER_DATA = USER_DATA.load("%s/%s.pkl" % (CONFIGURATION.config_dir, CONFIGURATION.assignment_id))

        # No point contacting elearning platform if no auth token is provided
        if CONFIGURATION.auth_token != "":
            USER_DATA = E_LEARNING.get_all_submissions(USER_DATA)
            if len(USER_DATA.db) > 0:
                USER_DATA = E_LEARNING.get_additional_user_info(USER_DATA)
                if CONFIGURATION.enforce_due_date:
                    CONFIGURATION.due_date = E_LEARNING.get_assignment_due_date()
                else:
                    CONFIGURATION.due_date = dateutil.parser.parse("2050-01-01 00:00:00 +00:00")  # a day in the future
                # Check if more than N times the same URL in usrdb
                USER_DATA.check_duplicate_url(same_url_limit=CONFIGURATION.same_url_limit)

        # Build Repository Object
        REPOSITORY = Repository(USER_DATA, LOGGER, CONFIGURATION, E_LEARNING)

        # Build Tester Object
        TESTER = Tester(USER_DATA, LOGGER, CONFIGURATION, E_LEARNING, REPOSITORY)

        if ARGS.forced_testing is not None:
            # Test specific user
            REPOSITORY.check_repository_changes([value.user_id for key, value in USER_DATA.db.items()
                                                 if value.user_fullname == ARGS.forced_testing][0])
            TESTER.process_student_assignment([value.user_id for key, value in USER_DATA.db.items()
                                               if value.user_fullname == ARGS.forced_testing][0], forced_testing=True)
        elif ARGS.repo_url_testing is not None:
            # Creating tmp user and simulating the test for the provided repository
            USER_DATA.db[1] = USER_DATA.User(user_id=1)
            USER_DATA.db[1].repository_url = ARGS.repo_url_testing
            USER_DATA.db[1].url_date = datetime(1, 1, 1, 0, 0).replace(tzinfo=timezone.utc)
            USER_DATA.db[1].new_url = True
            USER_DATA.db[1].commit_date = datetime(1, 1, 1, 0, 0).replace(tzinfo=timezone.utc)
            LOGGER.verbose = True
            LOGGER.print_debug_messages = True
            CONFIGURATION.simulate = True
            REPOSITORY.check_repository_changes(1)
            TESTER.process_student_assignment(1)
            LOGGER.vprint("Repo testing complete!")
            exit(0)
        else:
            # Start testing changed records (new or updated) if any exist
            LOGGER.vprint("Prefetching all user repositories")
            # Prefetching is important for group assignments where grade is submitted to multiple members and all
            # user dbs need to be updated later on
            reverse_repository_index = dict()
            for key, value in USER_DATA.db.items():
                if CONFIGURATION.no_repo is not True:
                    if value.repository_url is not None:
                        REPOSITORY.check_repository_changes(key)
                        # Create a reverse dictionary and obtain one name from a group (in case of group assignments)
                        # Process group assignment will test once and then it identifies and submits a grade for both
                        # groups
                        reverse_repository_index[value.repository_url] = key
                else:
                    # When no repo is involved it is 1 to 1 check for assignments
                    reverse_repository_index[key] = key
            processing_list = [[key, value] for key, value in USER_DATA.db.items() if
                               key in reverse_repository_index.values()]
            del reverse_repository_index

            # Whether we should run processes in parallel or not
            if CONFIGURATION.processes < 2:
                for key, value in processing_list:
                    USER_DATA.db[key] = TESTER.process_student_assignment(key)[0]  # because what is returned is a list
            else:
                compute_pool = multiprocessing.Pool(processes=CONFIGURATION.processes)
                user_object_results = compute_pool.map(TESTER.process_student_assignment,
                                                       [key for key, value in processing_list])
                for users_object in user_object_results:
                    for user_object in users_object:
                        USER_DATA.db[user_object.user_id] = user_object
            del processing_list

        # Initiate plagiarism checks
        if datetime.now(timezone.utc).hour == CONFIGURATION.check_plagiarism_hour:
            TESTER.plagiarism_checks_on_users()

        # Save database changes
        if CONFIGURATION.simulate is False:
            USER_DATA.save("%s/%s.pkl" % (CONFIGURATION.config_dir, CONFIGURATION.assignment_id))
            os.chmod("%s/%s.pkl" % (CONFIGURATION.config_dir, CONFIGURATION.assignment_id), 0o666)
        if LOGGER.verbose is False:
            subprocess.run("echo \"$(tail -3000 '%s')\" > '%s'" % (LOGGER.log_file, LOGGER.log_file), shell=True)
            os.chmod(LOGGER.log_file, 0o666)
        # In case this script is run as another user the repo needs to be also set to be editable by anyone
        try:
            os.chmod("%s/repodata%s" % (CONFIGURATION.config_dir, CONFIGURATION.assignment_id), 0o777)
        except FileNotFoundError:
            pass

        LOGGER.vprint("###\nFinished - %s\n###" % datetime.now(timezone.utc).isoformat(' '))

    # Closing statement
    lock.release()
